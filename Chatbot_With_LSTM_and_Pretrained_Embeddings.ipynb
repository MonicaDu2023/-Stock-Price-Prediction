{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8MfAt_T3qyqB"
   },
   "source": [
    "# Project Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLT3IJI6qyqE"
   },
   "source": [
    "In this project, I will build a chatbot that can converse with you at the command line. The chatbot will use a Sequence to Sequence text generation architecture with an LSTM as it's memory unit. You will also learn to use pretrained word embeddings to improve the performance of the model. At the conclusion of the project, you will be able to show your chatbot to potential employers.\n",
    "\n",
    "Additionally, you have the option to use pretrained word embeddings in your model. We have loaded Brown Embeddings from Gensim in the starter code below. You can compare the performance of your model with pre-trained embeddings against a model without the embeddings.\n",
    "\n",
    "A sequence to sequence model (Seq2Seq) has two components:\n",
    "\n",
    "An Encoder consisting of an embedding layer and LSTM unit.\n",
    "A Decoder consisting of an embedding layer, LSTM unit, and linear output unit.\n",
    "The Seq2Seq model works by accepting an input into the Encoder, passing the hidden state from the Encoder to the Decoder, which the Decoder uses to output a series of token predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TIsIz2XrqyqF",
    "outputId": "262bcf30-c53d-4496-dd50-54d03c2c5d69"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /Users/ante/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/ante/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import torch\n",
    "from nltk.corpus import brown\n",
    "from torchtext.datasets import SQuAD1\n",
    "import string\n",
    "import torch.nn as nn\n",
    "import random \n",
    "from sklearn.model_selection import KFold\n",
    "from datetime import datetime\n",
    "\n",
    "stemmer = nltk.stem.snowball.SnowballStemmer('english')\n",
    "\n",
    "nltk.download('brown')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Output, save, and load brown embeddings\n",
    "\n",
    "model = gensim.models.Word2Vec(brown.sents())\n",
    "model.save('brown.embedding')\n",
    "\n",
    "w2v = gensim.models.Word2Vec.load('brown.embedding')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "daGXVk29qyqH"
   },
   "outputs": [],
   "source": [
    "def loadDF(path):\n",
    "    \n",
    "    dataset_train, dataset_dev = SQuAD1(root = path, split = ('train', 'dev'))\n",
    "\n",
    "    df_train = pd.DataFrame.from_dict(dataset_train)\n",
    "    df_dev = pd.DataFrame.from_dict(dataset_dev)\n",
    "    \n",
    "    df = df_train.append(df_dev)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yTx5I6VtqyqH",
    "outputId": "ec579d1a-b764-445e-bcc1-7aadec7e1d50"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>[Saint Bernadette Soubirous]</td>\n",
       "      <td>[515]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>[a copper statue of Christ]</td>\n",
       "      <td>[188]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>[the Main Building]</td>\n",
       "      <td>[279]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>[a Marian place of prayer and reflection]</td>\n",
       "      <td>[381]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>[a golden statue of the Virgin Mary]</td>\n",
       "      <td>[92]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  \\\n",
       "0  Architecturally, the school has a Catholic cha...   \n",
       "1  Architecturally, the school has a Catholic cha...   \n",
       "2  Architecturally, the school has a Catholic cha...   \n",
       "3  Architecturally, the school has a Catholic cha...   \n",
       "4  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                                            Question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "1  What is in front of the Notre Dame Main Building?   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                  What is the Grotto at Notre Dame?   \n",
       "4  What sits on top of the Main Building at Notre...   \n",
       "\n",
       "                                      Answer      ?  \n",
       "0               [Saint Bernadette Soubirous]  [515]  \n",
       "1                [a copper statue of Christ]  [188]  \n",
       "2                        [the Main Building]  [279]  \n",
       "3  [a Marian place of prayer and reflection]  [381]  \n",
       "4       [a golden statue of the Virgin Mary]   [92]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = loadDF('.data')\n",
    "\n",
    "feature = [\"Sentence\", \"Question\", \"Answer\", \"?\"]\n",
    "df.columns = feature\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5DfmSYY5qyqI"
   },
   "outputs": [],
   "source": [
    "df = df[['Question', 'Answer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qAh6fxzfq4qk"
   },
   "outputs": [],
   "source": [
    "def normalize_sentence(sentence):\n",
    "    \n",
    "    sentence = ''.join([s.lower() for s in sentence if s not in string.punctuation])\n",
    "    sentence = ' '.join(stemmer.stem(w) for w in sentence.split())\n",
    "    #tokens = nltk.tokenize.RegexpTokenizer(r'\\w+').tokenize(sentence)\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tdRX3jdnrSHO"
   },
   "outputs": [],
   "source": [
    "df['Question'] = df['Question'].apply(normalize_sentence)\n",
    "df['Answer'] = df['Answer'].apply(normalize_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3qNG4-_TqyqI"
   },
   "outputs": [],
   "source": [
    "df_train = df.iloc[:10000, :]\n",
    "df_test = df.iloc[10000:20000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Er67i5oQqyqI",
    "outputId": "ce277a88-6200-4290-aba6-86add84024d1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>to whom did the virgin mari alleg appear in 18...</td>\n",
       "      <td>saint bernadett soubir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is in front of the notr dame main build</td>\n",
       "      <td>a copper statu of christ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the basilica of the sacr heart at notr dame is...</td>\n",
       "      <td>the main build</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what is the grotto at notr dame</td>\n",
       "      <td>a marian place of prayer and reflect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what sit on top of the main build at notr dame</td>\n",
       "      <td>a golden statu of the virgin mari</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  to whom did the virgin mari alleg appear in 18...   \n",
       "1       what is in front of the notr dame main build   \n",
       "2  the basilica of the sacr heart at notr dame is...   \n",
       "3                    what is the grotto at notr dame   \n",
       "4     what sit on top of the main build at notr dame   \n",
       "\n",
       "                                 Answer  \n",
       "0                saint bernadett soubir  \n",
       "1              a copper statu of christ  \n",
       "2                        the main build  \n",
       "3  a marian place of prayer and reflect  \n",
       "4     a golden statu of the virgin mari  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2fro-Ywyp_tW"
   },
   "outputs": [],
   "source": [
    "import torchtext\n",
    "import torch\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter\n",
    "from torchtext.vocab import vocab\n",
    "import spacy\n",
    "\n",
    "en_nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "en_tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "\n",
    "def build_vocab(df, caption, tokenizer):\n",
    "    default_index = 0\n",
    "    counter = Counter()\n",
    "    for index, row, in df.iterrows():\n",
    "        counter.update(tokenizer(row[caption]))\n",
    "    v2 = vocab(counter, specials=['<unk>', '<pad>', '<sos>', '<eos>'])\n",
    "    v2.set_default_index(default_index)\n",
    "    v2.set_default_index(v2['<unk>'])\n",
    "        \n",
    "    return v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ml_2Dzqsp_tW"
   },
   "outputs": [],
   "source": [
    "question_vocab = build_vocab(df_train, \"Question\", en_tokenizer)\n",
    "answer_vocab = build_vocab(df_train, \"Answer\", en_tokenizer)\n",
    "\n",
    "def data_process(df):\n",
    "    \n",
    "    data = []\n",
    "    for index, (question, answers) in df.iterrows():\n",
    "        question_tensor_ = torch.tensor([question_vocab[token] for token in en_tokenizer(question)],\n",
    "                            dtype=torch.long)\n",
    "        answer_tensor_ = torch.tensor([answer_vocab[token] for token in en_tokenizer(answers)],\n",
    "                            dtype=torch.long)\n",
    "        data.append((question_tensor_, answer_tensor_))\n",
    "    return data\n",
    "\n",
    "train_data = data_process(df_train)\n",
    "val_data = data_process(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "latu4DRQp_tX",
    "outputId": "cadb4383-a387-4b1d-e29a-ebcdbd3e3561"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 4,  5,  6,  7,  8,  9, 10, 11]), tensor([4, 5, 6]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r43kHOk_p_tX",
    "outputId": "160693a5-683b-48e4-c8cb-8aa2e2c6f3ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_vocab['<sos>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T-newh5Fp_tY",
    "outputId": "cde61ead-3cc2-4df5-bb8f-b1eca26e62b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cpu')\n",
    "print(device)\n",
    "BATCH_SIZE = 521\n",
    "PAD_IDX = question_vocab['<pad>']\n",
    "SOS_IDX = question_vocab['<sos>']\n",
    "EOS_IDX = question_vocab['<eos>']\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def generate_batch(data_batch):\n",
    "    de_batch, en_batch = [], []\n",
    "    for (de_item, en_item) in data_batch:\n",
    "        de_batch.append(torch.cat([torch.tensor([SOS_IDX]), de_item, torch.tensor([EOS_IDX])], dim=0))\n",
    "        en_batch.append(torch.cat([torch.tensor([SOS_IDX]), en_item, torch.tensor([EOS_IDX])], dim=0))\n",
    "        de = pad_sequence(de_batch, padding_value=PAD_IDX)\n",
    "        en = pad_sequence(en_batch, padding_value=PAD_IDX)\n",
    "    return de, en\n",
    "\n",
    "train_iter = DataLoader(train_data, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, collate_fn=generate_batch)\n",
    "valid_iter = DataLoader(val_data, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, collate_fn=generate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UbALXLp4p_tY",
    "outputId": "9b6cbc6a-2d51-4608-e09a-02c091f41397"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAD_IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vuPA5EUzp_tZ",
    "outputId": "598641a1-a289-448c-ad5d-e526efd26622"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iYK7gsKIp_tZ"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, emb_size, hidden_size, n_layers = 2, dropout = 0.5):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.emb_size = emb_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.input_size, self.emb_size)\n",
    "        # The LSTM is our last cell because it produces the hidden state\n",
    "        self.lstm = nn.LSTM(self.emb_size, self.hidden_size, self.n_layers)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.embedding(src)\n",
    "        \n",
    "        embedded = self.dropout(embedded)\n",
    "     \n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        \n",
    "        return hidden, cell   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jb2IH5Rrp_tZ"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size, emb_size, output_size, n_layers = 2, dropout = 0.5):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.emb_size = emb_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        # initialize every layer with the appropriate dimension.\n",
    "        self.embedding = nn.Embedding(output_size, self.emb_size)\n",
    "        self.lstm = nn.LSTM(self.emb_size, self.hidden_size, self.n_layers)\n",
    "        self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "\n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.embedding(input)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
    "             \n",
    "        prediction = self.softmax(self.fc(output.squeeze(0)))\n",
    "\n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5SGFQkXvp_tk"
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "     \n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 1):\n",
    "        \n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_size\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        hidden, cell = self.encoder(src)\n",
    "        \n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        input = trg[0,:]\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            \n",
    "            #insert input token embedding, previous hidden and previous cell states\n",
    "            #receive output tensor (predictions) and new hidden and cell states\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            \n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            \n",
    "            #decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            #get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1) \n",
    "            \n",
    "            #if teacher forcing, use actual next token as next input\n",
    "            #if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "        \n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "33Bw-s2Op_tl"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(question_vocab)\n",
    "OUTPUT_DIM = len(answer_vocab)\n",
    "HID_DIM = 128\n",
    "\n",
    "enc = Encoder(INPUT_DIM, 256, HID_DIM)\n",
    "\n",
    "dec = Decoder(HID_DIM, 256, OUTPUT_DIM)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2_PI1dUyp_tl",
    "outputId": "d067baf8-3662-4fbc-b854-d5bee0efef45"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(11768, 256)\n",
       "    (lstm): LSTM(256, 128, num_layers=2)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(10371, 256)\n",
       "    (lstm): LSTM(256, 128, num_layers=2)\n",
       "    (fc): Linear(in_features=128, out_features=10371, bias=True)\n",
       "    (softmax): LogSoftmax(dim=1)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aBPtgUZsp_tl",
    "outputId": "a7380118-0612-4c0c-f9f2-32b406093aca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 7,664,899 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def init_weights(m: nn.Module):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr= 0.01)\n",
    "\n",
    "def count_parameters(model: nn.Module):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZVsVMty3p_tq",
    "outputId": "0a79325a-ba55-4efe-df9a-c041b55aa241"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "PAD_IDX = question_vocab.get_stoi()['<pad>']\n",
    "print(PAD_IDX)\n",
    "criterion = nn.NLLLoss(ignore_index=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W9GbqAD_p_tq"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, clip):  \n",
    "\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for _, (src, trg) in enumerate(iterator):\n",
    "\n",
    "        src, trg = src.to(device), trg.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(src, trg)\n",
    "\n",
    "        output = output[1:].view(-1, output.shape[-1])\n",
    "        trg = trg[1:].view(-1)\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_TYWWvX0p_tr"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for _, (src, trg) in enumerate(iterator):\n",
    "            src, trg = src.to(device), trg.to(device)\n",
    "            output = model(src, trg, 0) #turn off teacher forcing\n",
    "\n",
    "            output = output[1:].view(-1, output.shape[-1])\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_qpCvbjqcmnf",
    "outputId": "7c9e220a-2cbd-41ce-cc1a-67f2eb043515"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 18s\n",
      "\tTrain Loss: 4.744\n",
      "\t Val. Loss: 3.257\n",
      "Epoch: 02 | Time: 0m 18s\n",
      "\tTrain Loss: 4.528\n",
      "\t Val. Loss: 3.227\n",
      "Epoch: 03 | Time: 0m 18s\n",
      "\tTrain Loss: 4.334\n",
      "\t Val. Loss: 3.320\n",
      "Epoch: 04 | Time: 0m 18s\n",
      "\tTrain Loss: 4.174\n",
      "\t Val. Loss: 3.364\n",
      "Epoch: 05 | Time: 0m 17s\n",
      "\tTrain Loss: 4.034\n",
      "\t Val. Loss: 3.293\n",
      "Epoch: 06 | Time: 0m 18s\n",
      "\tTrain Loss: 3.934\n",
      "\t Val. Loss: 3.278\n",
      "Epoch: 07 | Time: 0m 18s\n",
      "\tTrain Loss: 3.805\n",
      "\t Val. Loss: 3.352\n",
      "Epoch: 08 | Time: 0m 18s\n",
      "\tTrain Loss: 3.715\n",
      "\t Val. Loss: 3.453\n",
      "Epoch: 09 | Time: 0m 18s\n",
      "\tTrain Loss: 3.595\n",
      "\t Val. Loss: 3.396\n",
      "Epoch: 10 | Time: 0m 18s\n",
      "\tTrain Loss: 3.492\n",
      "\t Val. Loss: 3.503\n",
      "Epoch: 11 | Time: 0m 18s\n",
      "\tTrain Loss: 3.356\n",
      "\t Val. Loss: 3.585\n",
      "Epoch: 12 | Time: 0m 18s\n",
      "\tTrain Loss: 3.257\n",
      "\t Val. Loss: 3.573\n",
      "Epoch: 13 | Time: 0m 18s\n",
      "\tTrain Loss: 3.145\n",
      "\t Val. Loss: 3.720\n",
      "Epoch: 14 | Time: 0m 18s\n",
      "\tTrain Loss: 3.010\n",
      "\t Val. Loss: 3.616\n",
      "Epoch: 15 | Time: 0m 18s\n",
      "\tTrain Loss: 2.870\n",
      "\t Val. Loss: 4.014\n",
      "Epoch: 16 | Time: 0m 18s\n",
      "\tTrain Loss: 2.770\n",
      "\t Val. Loss: 3.874\n",
      "Epoch: 17 | Time: 0m 18s\n",
      "\tTrain Loss: 2.636\n",
      "\t Val. Loss: 4.087\n",
      "Epoch: 18 | Time: 0m 18s\n",
      "\tTrain Loss: 2.471\n",
      "\t Val. Loss: 4.013\n",
      "Epoch: 19 | Time: 0m 18s\n",
      "\tTrain Loss: 2.385\n",
      "\t Val. Loss: 4.074\n",
      "Epoch: 20 | Time: 0m 18s\n",
      "\tTrain Loss: 2.268\n",
      "\t Val. Loss: 4.093\n",
      "Epoch: 21 | Time: 0m 18s\n",
      "\tTrain Loss: 2.137\n",
      "\t Val. Loss: 4.177\n",
      "Epoch: 22 | Time: 0m 18s\n",
      "\tTrain Loss: 1.974\n",
      "\t Val. Loss: 4.420\n",
      "Epoch: 23 | Time: 0m 18s\n",
      "\tTrain Loss: 1.866\n",
      "\t Val. Loss: 4.297\n",
      "Epoch: 24 | Time: 0m 18s\n",
      "\tTrain Loss: 1.736\n",
      "\t Val. Loss: 4.439\n",
      "Epoch: 25 | Time: 0m 18s\n",
      "\tTrain Loss: 1.615\n",
      "\t Val. Loss: 4.477\n",
      "Epoch: 26 | Time: 0m 18s\n",
      "\tTrain Loss: 1.511\n",
      "\t Val. Loss: 4.549\n",
      "Epoch: 27 | Time: 0m 18s\n",
      "\tTrain Loss: 1.402\n",
      "\t Val. Loss: 4.660\n",
      "Epoch: 28 | Time: 0m 18s\n",
      "\tTrain Loss: 1.313\n",
      "\t Val. Loss: 4.820\n",
      "Epoch: 29 | Time: 0m 18s\n",
      "\tTrain Loss: 1.157\n",
      "\t Val. Loss: 4.815\n",
      "Epoch: 30 | Time: 0m 18s\n",
      "\tTrain Loss: 1.090\n",
      "\t Val. Loss: 4.814\n",
      "Epoch: 31 | Time: 0m 18s\n",
      "\tTrain Loss: 1.002\n",
      "\t Val. Loss: 5.027\n",
      "Epoch: 32 | Time: 0m 18s\n",
      "\tTrain Loss: 0.888\n",
      "\t Val. Loss: 4.988\n",
      "Epoch: 33 | Time: 0m 18s\n",
      "\tTrain Loss: 0.793\n",
      "\t Val. Loss: 5.048\n",
      "Epoch: 34 | Time: 0m 18s\n",
      "\tTrain Loss: 0.736\n",
      "\t Val. Loss: 5.090\n",
      "Epoch: 35 | Time: 0m 18s\n",
      "\tTrain Loss: 0.641\n",
      "\t Val. Loss: 5.211\n",
      "Epoch: 36 | Time: 0m 18s\n",
      "\tTrain Loss: 0.578\n",
      "\t Val. Loss: 5.332\n",
      "Epoch: 37 | Time: 0m 18s\n",
      "\tTrain Loss: 0.498\n",
      "\t Val. Loss: 5.366\n",
      "Epoch: 38 | Time: 0m 18s\n",
      "\tTrain Loss: 0.442\n",
      "\t Val. Loss: 5.503\n",
      "Epoch: 39 | Time: 0m 18s\n",
      "\tTrain Loss: 0.382\n",
      "\t Val. Loss: 5.618\n",
      "Epoch: 40 | Time: 0m 18s\n",
      "\tTrain Loss: 0.353\n",
      "\t Val. Loss: 5.740\n",
      "Epoch: 41 | Time: 0m 18s\n",
      "\tTrain Loss: 0.309\n",
      "\t Val. Loss: 5.751\n",
      "Epoch: 42 | Time: 0m 18s\n",
      "\tTrain Loss: 0.265\n",
      "\t Val. Loss: 5.835\n",
      "Epoch: 43 | Time: 0m 18s\n",
      "\tTrain Loss: 0.235\n",
      "\t Val. Loss: 5.928\n",
      "Epoch: 44 | Time: 0m 18s\n",
      "\tTrain Loss: 0.220\n",
      "\t Val. Loss: 5.998\n",
      "Epoch: 45 | Time: 0m 18s\n",
      "\tTrain Loss: 0.204\n",
      "\t Val. Loss: 6.013\n",
      "Epoch: 46 | Time: 0m 18s\n",
      "\tTrain Loss: 0.180\n",
      "\t Val. Loss: 6.200\n",
      "Epoch: 47 | Time: 0m 18s\n",
      "\tTrain Loss: 0.159\n",
      "\t Val. Loss: 6.193\n",
      "Epoch: 48 | Time: 0m 18s\n",
      "\tTrain Loss: 0.142\n",
      "\t Val. Loss: 6.170\n",
      "Epoch: 49 | Time: 0m 18s\n",
      "\tTrain Loss: 0.132\n",
      "\t Val. Loss: 6.385\n",
      "Epoch: 50 | Time: 0m 18s\n",
      "\tTrain Loss: 0.119\n",
      "\t Val. Loss: 6.346\n",
      "Epoch: 51 | Time: 0m 18s\n",
      "\tTrain Loss: 0.106\n",
      "\t Val. Loss: 6.525\n",
      "Epoch: 52 | Time: 0m 18s\n",
      "\tTrain Loss: 0.105\n",
      "\t Val. Loss: 6.543\n",
      "Epoch: 53 | Time: 0m 18s\n",
      "\tTrain Loss: 0.097\n",
      "\t Val. Loss: 6.620\n",
      "Epoch: 54 | Time: 0m 18s\n",
      "\tTrain Loss: 0.090\n",
      "\t Val. Loss: 6.700\n",
      "Epoch: 55 | Time: 0m 18s\n",
      "\tTrain Loss: 0.082\n",
      "\t Val. Loss: 6.595\n",
      "Epoch: 56 | Time: 0m 18s\n",
      "\tTrain Loss: 0.076\n",
      "\t Val. Loss: 6.750\n",
      "Epoch: 57 | Time: 0m 18s\n",
      "\tTrain Loss: 0.074\n",
      "\t Val. Loss: 6.798\n",
      "Epoch: 58 | Time: 0m 18s\n",
      "\tTrain Loss: 0.069\n",
      "\t Val. Loss: 6.737\n",
      "Epoch: 59 | Time: 0m 18s\n",
      "\tTrain Loss: 0.064\n",
      "\t Val. Loss: 6.810\n",
      "Epoch: 60 | Time: 0m 18s\n",
      "\tTrain Loss: 0.068\n",
      "\t Val. Loss: 6.860\n",
      "Epoch: 61 | Time: 0m 18s\n",
      "\tTrain Loss: 0.068\n",
      "\t Val. Loss: 6.894\n",
      "Epoch: 62 | Time: 0m 18s\n",
      "\tTrain Loss: 0.065\n",
      "\t Val. Loss: 6.830\n",
      "Epoch: 63 | Time: 0m 18s\n",
      "\tTrain Loss: 0.065\n",
      "\t Val. Loss: 6.875\n",
      "Epoch: 64 | Time: 0m 18s\n",
      "\tTrain Loss: 0.061\n",
      "\t Val. Loss: 6.867\n",
      "Epoch: 65 | Time: 0m 18s\n",
      "\tTrain Loss: 0.060\n",
      "\t Val. Loss: 6.955\n",
      "Epoch: 66 | Time: 0m 18s\n",
      "\tTrain Loss: 0.063\n",
      "\t Val. Loss: 7.027\n",
      "Epoch: 67 | Time: 0m 18s\n",
      "\tTrain Loss: 0.058\n",
      "\t Val. Loss: 7.057\n",
      "Epoch: 68 | Time: 0m 18s\n",
      "\tTrain Loss: 0.058\n",
      "\t Val. Loss: 7.155\n",
      "Epoch: 69 | Time: 0m 18s\n",
      "\tTrain Loss: 0.064\n",
      "\t Val. Loss: 6.993\n",
      "Epoch: 70 | Time: 0m 18s\n",
      "\tTrain Loss: 0.060\n",
      "\t Val. Loss: 7.056\n",
      "Epoch: 71 | Time: 0m 18s\n",
      "\tTrain Loss: 0.055\n",
      "\t Val. Loss: 7.078\n",
      "Epoch: 72 | Time: 0m 18s\n",
      "\tTrain Loss: 0.046\n",
      "\t Val. Loss: 7.124\n",
      "Epoch: 73 | Time: 0m 18s\n",
      "\tTrain Loss: 0.046\n",
      "\t Val. Loss: 7.105\n",
      "Epoch: 74 | Time: 0m 18s\n",
      "\tTrain Loss: 0.048\n",
      "\t Val. Loss: 7.266\n",
      "Epoch: 75 | Time: 0m 18s\n",
      "\tTrain Loss: 0.046\n",
      "\t Val. Loss: 7.186\n",
      "Epoch: 76 | Time: 0m 18s\n",
      "\tTrain Loss: 0.047\n",
      "\t Val. Loss: 7.326\n",
      "Epoch: 77 | Time: 0m 18s\n",
      "\tTrain Loss: 0.049\n",
      "\t Val. Loss: 7.374\n",
      "Epoch: 78 | Time: 0m 18s\n",
      "\tTrain Loss: 0.053\n",
      "\t Val. Loss: 7.311\n",
      "Epoch: 79 | Time: 0m 18s\n",
      "\tTrain Loss: 0.047\n",
      "\t Val. Loss: 7.421\n",
      "Epoch: 80 | Time: 0m 18s\n",
      "\tTrain Loss: 0.042\n",
      "\t Val. Loss: 7.401\n",
      "Epoch: 81 | Time: 0m 18s\n",
      "\tTrain Loss: 0.042\n",
      "\t Val. Loss: 7.379\n",
      "Epoch: 82 | Time: 0m 18s\n",
      "\tTrain Loss: 0.042\n",
      "\t Val. Loss: 7.310\n",
      "Epoch: 83 | Time: 0m 18s\n",
      "\tTrain Loss: 0.052\n",
      "\t Val. Loss: 7.454\n",
      "Epoch: 84 | Time: 0m 18s\n",
      "\tTrain Loss: 0.061\n",
      "\t Val. Loss: 7.360\n",
      "Epoch: 85 | Time: 0m 18s\n",
      "\tTrain Loss: 0.052\n",
      "\t Val. Loss: 7.335\n",
      "Epoch: 86 | Time: 0m 18s\n",
      "\tTrain Loss: 0.044\n",
      "\t Val. Loss: 7.464\n",
      "Epoch: 87 | Time: 0m 18s\n",
      "\tTrain Loss: 0.043\n",
      "\t Val. Loss: 7.320\n",
      "Epoch: 88 | Time: 0m 18s\n",
      "\tTrain Loss: 0.047\n",
      "\t Val. Loss: 7.302\n",
      "Epoch: 89 | Time: 0m 18s\n",
      "\tTrain Loss: 0.045\n",
      "\t Val. Loss: 7.289\n",
      "Epoch: 90 | Time: 0m 19s\n",
      "\tTrain Loss: 0.047\n",
      "\t Val. Loss: 7.448\n",
      "Epoch: 91 | Time: 0m 19s\n",
      "\tTrain Loss: 0.036\n",
      "\t Val. Loss: 7.599\n",
      "Epoch: 92 | Time: 0m 19s\n",
      "\tTrain Loss: 0.040\n",
      "\t Val. Loss: 7.378\n",
      "Epoch: 93 | Time: 0m 19s\n",
      "\tTrain Loss: 0.042\n",
      "\t Val. Loss: 7.534\n",
      "Epoch: 94 | Time: 0m 18s\n",
      "\tTrain Loss: 0.045\n",
      "\t Val. Loss: 7.581\n",
      "Epoch: 95 | Time: 0m 18s\n",
      "\tTrain Loss: 0.049\n",
      "\t Val. Loss: 7.469\n",
      "Epoch: 96 | Time: 0m 18s\n",
      "\tTrain Loss: 0.033\n",
      "\t Val. Loss: 7.641\n",
      "Epoch: 97 | Time: 0m 18s\n",
      "\tTrain Loss: 0.034\n",
      "\t Val. Loss: 7.600\n",
      "Epoch: 98 | Time: 0m 18s\n",
      "\tTrain Loss: 0.033\n",
      "\t Val. Loss: 7.635\n",
      "Epoch: 99 | Time: 0m 18s\n",
      "\tTrain Loss: 0.029\n",
      "\t Val. Loss: 7.676\n",
      "Epoch: 100 | Time: 0m 18s\n",
      "\tTrain Loss: 0.027\n",
      "\t Val. Loss: 7.685\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 100\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(model, train_iter, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iter, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'seq2seq_model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X-w5pyyUp_tt",
    "outputId": "287ecbc5-9b6b-4ffc-f193-5c0e5000878f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('seq2seq_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QkbPc2YBp_tt"
   },
   "outputs": [],
   "source": [
    "def chatbot(model, iterator, criterion):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for _, (src, trg) in enumerate(iterator):\n",
    "            src, trg = src.to(device), trg.to(device)\n",
    "            output = model(src, trg, 0) #turn off teacher forcing\n",
    "            output = output[1:].view(-1, output.shape[-1])\n",
    "            trg = trg[1:].view(-1)\n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            result = []\n",
    "            for tensor in output:\n",
    "                _, top_token = tensor.data.topk(1)\n",
    "                if top_token.item() == 1:\n",
    "                    break\n",
    "                else:\n",
    "                    word = answer_vocab.get_itos()[top_token.item()]\n",
    "                    result.append(word)     \n",
    "            return  result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RMHPOIJViNeI"
   },
   "outputs": [],
   "source": [
    "def generate_test_batch(data_batch):\n",
    "    de_batch, en_batch = [], []\n",
    "    for (de_item, en_item) in data_batch:\n",
    "        de_batch.append(torch.cat([torch.tensor([SOS_IDX]), de_item, torch.tensor([EOS_IDX])], dim=0))\n",
    "        en_batch.append(torch.cat([torch.tensor([SOS_IDX]), en_item, torch.tensor([EOS_IDX])], dim=0))\n",
    "        de = pad_sequence(de_batch, padding_value=PAD_IDX)\n",
    "        en = pad_sequence(en_batch, padding_value=PAD_IDX)\n",
    "    return de, en\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d0KM6OM_i5gR"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "dt_test = df_train.sample(n = 3)\n",
    "\n",
    "dt_test_1 = dt_test[0:1]\n",
    "dt_test_2 = dt_test[1:2]\n",
    "dt_test_3 = dt_test[2:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-6ULdPhViskO",
    "outputId": "325a3bbe-16de-4e35-bd51-21ab8c434419"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               question answers\n",
      "4148  If someone serves three consecutive terms as m...    four\n",
      "Answer: ['four', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "print(dt_test_1)\n",
    "test_data = data_process(dt_test_1)\n",
    "test_iter = DataLoader(test_data, batch_size=BATCH_SIZE,\n",
    "                       shuffle=True, collate_fn=generate_test_batch)\n",
    "\n",
    "next(iter(test_iter))\n",
    "\n",
    "result = chatbot(model, test_iter, criterion)\n",
    "print('Answer:', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GV4V0f9siskP",
    "outputId": "35093b26-8bc8-497f-b332-8ee40197d28d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               question            answers\n",
      "4528  Over 90% of homes use solar hot water systems ...  Israel and Cyprus\n",
      "Answer: ['Israel', 'and', 'Cyprus', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "print(dt_test_2)\n",
    "test_data = data_process(dt_test_2)\n",
    "test_iter = DataLoader(test_data, batch_size=BATCH_SIZE,\n",
    "                       shuffle=True, collate_fn=generate_test_batch)\n",
    "\n",
    "next(iter(test_iter))\n",
    "\n",
    "result = chatbot(model, test_iter, criterion)\n",
    "print('Answer:', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HZp6k6YuiskQ",
    "outputId": "4398273e-918b-43b7-9ef2-7424e74b9d23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             question           answers\n",
      "941  While in Berlin he saw the operatic work of who?  Gaspare Spontini\n",
      "Answer: ['Gaspare', 'Spontini', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "print(dt_test_3)\n",
    "test_data = data_process(dt_test_3)\n",
    "test_iter = DataLoader(test_data, batch_size=BATCH_SIZE,\n",
    "                       shuffle=True, collate_fn=generate_test_batch)\n",
    "\n",
    "next(iter(test_iter))\n",
    "\n",
    "result = chatbot(model, test_iter, criterion)\n",
    "print('Answer:', result)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
